{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 1.921587586402893,
      "learning_rate": 4.88e-05,
      "loss": 3.2758,
      "step": 10
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.770964503288269,
      "learning_rate": 4.746666666666667e-05,
      "loss": 2.78,
      "step": 20
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.2517566680908203,
      "learning_rate": 4.6133333333333334e-05,
      "loss": 2.382,
      "step": 30
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0255109071731567,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 1.9636,
      "step": 40
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8996555209159851,
      "learning_rate": 4.346666666666667e-05,
      "loss": 1.7192,
      "step": 50
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0305533409118652,
      "learning_rate": 4.213333333333334e-05,
      "loss": 1.504,
      "step": 60
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.100677490234375,
      "learning_rate": 4.08e-05,
      "loss": 1.4094,
      "step": 70
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.984258234500885,
      "learning_rate": 3.9466666666666666e-05,
      "loss": 1.3297,
      "step": 80
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.1155208349227905,
      "learning_rate": 3.8133333333333336e-05,
      "loss": 1.3278,
      "step": 90
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.177903652191162,
      "learning_rate": 3.68e-05,
      "loss": 1.2479,
      "step": 100
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.191908359527588,
      "learning_rate": 3.546666666666667e-05,
      "loss": 1.1564,
      "step": 110
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3006131649017334,
      "learning_rate": 3.4133333333333334e-05,
      "loss": 1.103,
      "step": 120
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.0878658294677734,
      "eval_runtime": 37.9362,
      "eval_samples_per_second": 26.36,
      "eval_steps_per_second": 3.295,
      "step": 125
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.6958012580871582,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 1.0694,
      "step": 130
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.698280692100525,
      "learning_rate": 3.146666666666667e-05,
      "loss": 1.0196,
      "step": 140
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.8169240951538086,
      "learning_rate": 3.0133333333333335e-05,
      "loss": 1.0317,
      "step": 150
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.5036581754684448,
      "learning_rate": 2.88e-05,
      "loss": 1.002,
      "step": 160
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.679781198501587,
      "learning_rate": 2.746666666666667e-05,
      "loss": 0.9902,
      "step": 170
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.996629238128662,
      "learning_rate": 2.6133333333333333e-05,
      "loss": 0.8529,
      "step": 180
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.5486576557159424,
      "learning_rate": 2.48e-05,
      "loss": 0.8932,
      "step": 190
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.7595179080963135,
      "learning_rate": 2.3466666666666667e-05,
      "loss": 0.9323,
      "step": 200
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 2.4146981239318848,
      "learning_rate": 2.2133333333333334e-05,
      "loss": 0.9109,
      "step": 210
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.9644801616668701,
      "learning_rate": 2.08e-05,
      "loss": 0.8575,
      "step": 220
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.0423877239227295,
      "learning_rate": 1.9466666666666668e-05,
      "loss": 0.851,
      "step": 230
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.8837544918060303,
      "learning_rate": 1.8133333333333335e-05,
      "loss": 0.8279,
      "step": 240
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.6284421682357788,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.8103,
      "step": 250
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8546313643455505,
      "eval_runtime": 37.8455,
      "eval_samples_per_second": 26.423,
      "eval_steps_per_second": 3.303,
      "step": 250
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.057119846343994,
      "learning_rate": 1.546666666666667e-05,
      "loss": 0.7776,
      "step": 260
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.8315136432647705,
      "learning_rate": 1.4133333333333334e-05,
      "loss": 0.8395,
      "step": 270
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.023706912994385,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.7627,
      "step": 280
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.3726069927215576,
      "learning_rate": 1.1466666666666666e-05,
      "loss": 0.7987,
      "step": 290
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.4601263999938965,
      "learning_rate": 1.0133333333333333e-05,
      "loss": 0.7852,
      "step": 300
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.0243592262268066,
      "learning_rate": 8.8e-06,
      "loss": 0.8225,
      "step": 310
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.2977211475372314,
      "learning_rate": 7.4666666666666675e-06,
      "loss": 0.8135,
      "step": 320
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.861877202987671,
      "learning_rate": 6.133333333333334e-06,
      "loss": 0.7349,
      "step": 330
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 2.163787364959717,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.7984,
      "step": 340
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.8910229206085205,
      "learning_rate": 3.466666666666667e-06,
      "loss": 0.805,
      "step": 350
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.9093494415283203,
      "learning_rate": 2.1333333333333334e-06,
      "loss": 0.8151,
      "step": 360
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.0131356716156006,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.7977,
      "step": 370
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8124153017997742,
      "eval_runtime": 37.902,
      "eval_samples_per_second": 26.384,
      "eval_steps_per_second": 3.298,
      "step": 375
    }
  ],
  "logging_steps": 10,
  "max_steps": 375,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 734922915840000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
